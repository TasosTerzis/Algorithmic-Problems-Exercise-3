{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3884948966312427430\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "# from IPython.display import Math, HTML\n",
    "import keras\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Flatten, Dense, Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of MNIST train images: (10000, 28, 28)\n",
      "Shape of MNIST test images: (4000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# load dataset\n",
    "(train_data, y_train),(test_data, y_test) = mnist.load_data()\n",
    "\n",
    "# keep 10k images for train data\n",
    "train_data = train_data[:10000]\n",
    "\n",
    "# keep 4k images for test data\n",
    "test_data = test_data[:4000]\n",
    "\n",
    "# Print the shape of the data\n",
    "print(f'Shape of MNIST train images: {train_data.shape}')\n",
    "print(f'Shape of MNIST test images: {test_data.shape}')\n",
    "\n",
    "# Display 9 random images in training data\n",
    "fig, ax = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[i, j].imshow(train_data[np.random.randint(0, 10000)], cmap='gray')\n",
    "        ax[i, j].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of MNIST images: (10000, 28, 28, 1)\n",
      "Type of MNIST train images: float32\n",
      "Type of MNIST test images: float32\n",
      "Range of MNIST test images: 0.0 to 1.0\n",
      "Range of MNIST train images: 0.0 to 1.0\n",
      "Shape of training data: (8000, 28, 28, 1)\n",
      "Shape of validation data: (2000, 28, 28, 1)\n",
      "Shape of training labels: (8000, 28, 28, 1)\n",
      "Shape of validation labels: (2000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.reshape(-1, 28, 28, 1)\n",
    "test_data = test_data.reshape(-1, 28, 28, 1)\n",
    "# check the shape of the data\n",
    "print(f'Shape of MNIST images: {train_data.shape}')\n",
    "\n",
    "# convert the data type to float32\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "\n",
    "# check the type of the data\n",
    "print(f'Type of MNIST train images: {train_data.dtype}')\n",
    "print(f'Type of MNIST test images: {test_data.dtype}')\n",
    "\n",
    "\n",
    "# normalize the data\n",
    "train_data = train_data / np.max(train_data)\n",
    "test_data = test_data / np.max(test_data)\n",
    "\n",
    "# check the range of the data\n",
    "print(f'Range of MNIST test images: {train_data.min()} to {train_data.max()}')\n",
    "print(f'Range of MNIST train images: {test_data.min()} to {test_data.max()}')\n",
    "\n",
    "# parition the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, valid_X, train_ground, valid_ground = train_test_split(train_data,\n",
    "                                                                train_data,\n",
    "                                                                test_size=0.2)\n",
    "\n",
    "# print the shape of training data and validation data\n",
    "print(f'Shape of training data: {train_X.shape}')\n",
    "print(f'Shape of validation data: {valid_X.shape}')\n",
    "\n",
    "print(f'Shape of training labels: {train_ground.shape}')\n",
    "print(f'Shape of validation labels: {valid_ground.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "inChannel = 1\n",
    "x, y = 28, 28\n",
    "input_img = Input(shape=(x, y, inChannel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of flattened layer: (None, 6272)\n",
      "Shape of bottleneck layer: (None, 28)\n",
      "Shape of flattened layer: (None, 6272)\n",
      "Shape of bottleneck layer: (None, 28)\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_78 (Conv2D)          (None, 28, 28, 32)        1600      \n",
      "                                                                 \n",
      " batch_normalization_68 (Bat  (None, 28, 28, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_79 (Conv2D)          (None, 14, 14, 64)        100416    \n",
      "                                                                 \n",
      " batch_normalization_69 (Bat  (None, 14, 14, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 7, 7, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_80 (Conv2D)          (None, 7, 7, 128)         401536    \n",
      "                                                                 \n",
      " batch_normalization_70 (Bat  (None, 7, 7, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 28)                175644    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 680,092\n",
      "Trainable params: 679,644\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 28)]              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 6272)              181888    \n",
      "                                                                 \n",
      " reshape_10 (Reshape)        (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_81 (Conv2D)          (None, 7, 7, 128)         802944    \n",
      "                                                                 \n",
      " batch_normalization_71 (Bat  (None, 7, 7, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_20 (UpSamplin  (None, 14, 14, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_82 (Conv2D)          (None, 14, 14, 64)        401472    \n",
      "                                                                 \n",
      " batch_normalization_72 (Bat  (None, 14, 14, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_21 (UpSamplin  (None, 28, 28, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 28, 28, 1)         3137      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,390,209\n",
      "Trainable params: 1,389,825\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_84 (Conv2D)          (None, 28, 28, 32)        1600      \n",
      "                                                                 \n",
      " batch_normalization_73 (Bat  (None, 28, 28, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_85 (Conv2D)          (None, 14, 14, 64)        100416    \n",
      "                                                                 \n",
      " batch_normalization_74 (Bat  (None, 14, 14, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 7, 7, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_86 (Conv2D)          (None, 7, 7, 128)         401536    \n",
      "                                                                 \n",
      " batch_normalization_75 (Bat  (None, 7, 7, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 28)                175644    \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 6272)              181888    \n",
      "                                                                 \n",
      " reshape_11 (Reshape)        (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_87 (Conv2D)          (None, 7, 7, 128)         802944    \n",
      "                                                                 \n",
      " batch_normalization_76 (Bat  (None, 7, 7, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_22 (UpSamplin  (None, 14, 14, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_88 (Conv2D)          (None, 14, 14, 64)        401472    \n",
      "                                                                 \n",
      " batch_normalization_77 (Bat  (None, 14, 14, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_23 (UpSamplin  (None, 28, 28, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_89 (Conv2D)          (None, 28, 28, 1)         3137      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,070,301\n",
      "Trainable params: 2,069,469\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Latent dimension (change the size as needed)\n",
    "latent_dim = 28\n",
    "\n",
    "def encoder(input_img):\n",
    "    # Encoder layers\n",
    "    conv1 = Conv2D(32, (7, 7), activation='relu', padding='same')(input_img)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(64, (7, 7), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(128, (7, 7), activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    # create a flattened layer\n",
    "    flat = Flatten()(conv3)\n",
    "    # print the shape of the flattened layer\n",
    "    print(f'Shape of flattened layer: {flat.shape}')\n",
    "\n",
    "    # create a bottleneck layer\n",
    "    bottleneck = Dense(latent_dim, activation='relu')(flat)\n",
    "\n",
    "    # print the shape of the bottleneck layer\n",
    "    print(f'Shape of bottleneck layer: {bottleneck.shape}')\n",
    "\n",
    "    return bottleneck\n",
    "\n",
    "def decoder(bottleneck):\n",
    "    # Reshape the bottleneck to fit the convolutional layers\n",
    "    reshape_bottleneck = Dense(7 * 7 * 128, activation='relu')(bottleneck)\n",
    "    reshape_bottleneck = Reshape((7, 7, 128))(reshape_bottleneck)\n",
    "\n",
    "    # Decoder layers\n",
    "    conv4 = Conv2D(128, (7, 7), activation='relu', padding='same')(reshape_bottleneck)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    up1 = UpSampling2D((2, 2))(conv4)\n",
    "    conv5 = Conv2D(64, (7, 7), activation='relu', padding='same')(up1)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    up2 = UpSampling2D((2, 2))(conv5)\n",
    "    conv6 = Conv2D(1, (7, 7), activation='sigmoid', padding='same')(up2)\n",
    "\n",
    "    return conv6\n",
    "\n",
    "# Input layer\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "# Create the encoder and decoder models\n",
    "encoder_model = Model(input_img, encoder(input_img))\n",
    "\n",
    "# decoder model\n",
    "input_decoder = Input(shape=(latent_dim,))\n",
    "output_decoder = decoder(input_decoder)\n",
    "decoder_model = Model(input_decoder, output_decoder)\n",
    "\n",
    "# autoencoder model\n",
    "autoencoder_model = Model(input_img, decoder(encoder(input_img)))\n",
    "\n",
    "# Compile the autoencoder model\n",
    "encoder_model.compile(loss='mean_squared_error', optimizer=RMSprop(0.01))\n",
    "decoder_model.compile(loss='mean_squared_error', optimizer=RMSprop(0.01))\n",
    "autoencoder_model.compile(loss='mean_squared_error', optimizer=RMSprop(0.01))\n",
    "\n",
    "# Print model summaries\n",
    "encoder_model.summary()\n",
    "decoder_model.summary()\n",
    "autoencoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 3/63 [>.............................] - ETA: 1:47 - loss: 0.3347"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m autoencoder_train \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ground\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_ground\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder_train = autoencoder_model.fit(train_X, train_ground, batch_size=batch_size, epochs=epochs, verbose=1,validation_data=(valid_X, valid_ground))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = autoencoder_train.history['loss']\n",
    "val_loss = autoencoder_train.history['val_loss']\n",
    "epochs = range(epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, '-r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, '-g', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "autoencoder_model.save('autoencoder.h5')\n",
    "decoder_model.save('decoder.h5')\n",
    "encoder_model.save('encoder.h5')\\\n",
    "\n",
    "# Predict the autoencoder output from test images\n",
    "pred = autoencoder_model.predict(test_data)\n",
    "\n",
    "# # Plot the original test images and their reconstructions\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "# for images, row in zip([test_data, pred], axes):\n",
    "#     for img, ax in zip(images, row):\n",
    "#         ax.imshow(img.reshape((28, 28)), cmap='gray')\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "#         ax.get_yaxis().set_visible(False)\n",
    "# plt.show()\n",
    "\n",
    "# Predict the encoder output from test images\n",
    "encoded_data = encoder_model.predict(test_data)\n",
    "\n",
    "# # Display the encoded representations\n",
    "# fig, axes = plt.subplots(nrows=10, ncols=10, figsize=(20, 20))\n",
    "# for i in range(10):  # Iterate over each encoded dimension\n",
    "#     for j in range(10):  # Iterate over 10 images\n",
    "#         # Select the i-th channel from the j-th image\n",
    "#         channel_img = encoded_data[j, :, :, i]\n",
    "\n",
    "#         # Plot the 7x7 image\n",
    "#         axes[i, j].imshow(channel_img, cmap='gray')\n",
    "#         axes[i, j].get_xaxis().set_visible(False)\n",
    "#         axes[i, j].get_yaxis().set_visible(False)\n",
    "# plt.show()\n",
    "\n",
    "# Generate 10 random indices\n",
    "random_indices = np.random.choice(test_data.shape[0], size=10, replace=False)\n",
    "\n",
    "for j in range(10):\n",
    "    index = random_indices[j]\n",
    "    print(\n",
    "        f'=========================================================== Image {j+1} ===========================================================')\n",
    "    # Display the original image in a separate plot\n",
    "    fig_original, ax_original = plt.subplots(figsize=(2, 2))\n",
    "    ax_original.imshow(test_data[index, :, :, 0], cmap='gray')\n",
    "    ax_original.set_title('Original')\n",
    "    ax_original.get_xaxis().set_visible(False)\n",
    "    ax_original.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "    # Display the image after reconstruction\n",
    "    fig_reconstructed, ax_reconstructed = plt.subplots(figsize=(2, 2))\n",
    "    ax_reconstructed.imshow(pred[index, :, :, 0], cmap='gray')\n",
    "    ax_reconstructed.set_title('Reconstructed')\n",
    "    ax_reconstructed.get_xaxis().set_visible(False)\n",
    "    ax_reconstructed.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
