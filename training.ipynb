{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 17:14:45.311832: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16777252202746157990\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "# from IPython.display import Math, HTML\n",
    "import keras\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Flatten, Dense, Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of MNIST train images: (10000, 28, 28)\n",
      "Shape of MNIST test images: (4000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# load dataset\n",
    "(train_data, y_train),(test_data, y_test) = mnist.load_data()\n",
    "\n",
    "# keep 10k images for train data\n",
    "train_data = train_data[:10000]\n",
    "\n",
    "# keep 4k images for test data\n",
    "test_data = test_data[:4000]\n",
    "\n",
    "# Print the shape of the data\n",
    "print(f'Shape of MNIST train images: {train_data.shape}')\n",
    "print(f'Shape of MNIST test images: {test_data.shape}')\n",
    "\n",
    "# Display 9 random images in training data\n",
    "fig, ax = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[i, j].imshow(train_data[np.random.randint(0, 10000)], cmap='gray')\n",
    "        ax[i, j].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of MNIST images: (10000, 28, 28, 1)\n",
      "Type of MNIST train images: float32\n",
      "Type of MNIST test images: float32\n",
      "Range of MNIST test images: 0.0 to 1.0\n",
      "Range of MNIST train images: 0.0 to 1.0\n",
      "Shape of training data: (8000, 28, 28, 1)\n",
      "Shape of validation data: (2000, 28, 28, 1)\n",
      "Shape of training labels: (8000, 28, 28, 1)\n",
      "Shape of validation labels: (2000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.reshape(-1, 28, 28, 1)\n",
    "test_data = test_data.reshape(-1, 28, 28, 1)\n",
    "# check the shape of the data\n",
    "print(f'Shape of MNIST images: {train_data.shape}')\n",
    "\n",
    "# convert the data type to float32\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "\n",
    "# check the type of the data\n",
    "print(f'Type of MNIST train images: {train_data.dtype}')\n",
    "print(f'Type of MNIST test images: {test_data.dtype}')\n",
    "\n",
    "\n",
    "# normalize the data\n",
    "train_data = train_data / np.max(train_data)\n",
    "test_data = test_data / np.max(test_data)\n",
    "\n",
    "# check the range of the data\n",
    "print(f'Range of MNIST test images: {train_data.min()} to {train_data.max()}')\n",
    "print(f'Range of MNIST train images: {test_data.min()} to {test_data.max()}')\n",
    "\n",
    "# parition the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, valid_X, train_ground, valid_ground = train_test_split(train_data,\n",
    "                                                                train_data,\n",
    "                                                                test_size=0.2)\n",
    "\n",
    "# print the shape of training data and validation data\n",
    "print(f'Shape of training data: {train_X.shape}')\n",
    "print(f'Shape of validation data: {valid_X.shape}')\n",
    "\n",
    "print(f'Shape of training labels: {train_ground.shape}')\n",
    "print(f'Shape of validation labels: {valid_ground.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "inChannel = 1\n",
    "x, y = 28, 28\n",
    "input_img = Input(shape=(x, y, inChannel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 17:14:50.636082: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of flattened layer: (None, 6272)\n",
      "Shape of bottleneck layer: (None, 28)\n",
      "Shape of flattened layer: (None, 6272)\n",
      "Shape of bottleneck layer: (None, 28)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        1600      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        100416    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 128)         401536    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28)                175644    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 680,092\n",
      "Trainable params: 679,644\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 32)        1600      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 64)        100416    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 128)         401536    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 28)                175644    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6272)              181888    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 7, 7, 128)         802944    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 14, 14, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 14, 14, 64)        401472    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 28, 28, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 1)         3137      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,070,301\n",
      "Trainable params: 2,069,469\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Latent dimension (change the size as needed)\n",
    "latent_dim = 28\n",
    "\n",
    "def encoder(input_img):\n",
    "    # Encoder layers\n",
    "    conv1 = Conv2D(32, (7, 7), activation='relu', padding='same')(input_img)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(64, (7, 7), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(128, (7, 7), activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    # create a flattened layer\n",
    "    flat = Flatten()(conv3)\n",
    "    # print the shape of the flattened layer\n",
    "    print(f'Shape of flattened layer: {flat.shape}')\n",
    "\n",
    "    # create a bottleneck layer\n",
    "    bottleneck = Dense(latent_dim, activation='relu')(flat)\n",
    "\n",
    "    # print the shape of the bottleneck layer\n",
    "    print(f'Shape of bottleneck layer: {bottleneck.shape}')\n",
    "\n",
    "    return bottleneck\n",
    "\n",
    "# Define the decoder function\n",
    "def decoder(bottleneck):\n",
    "    reshape_bottleneck = Dense(7 * 7 * 128, activation='relu')(bottleneck)\n",
    "    reshape_bottleneck = Reshape((7, 7, 128))(reshape_bottleneck)\n",
    "\n",
    "    conv4 = Conv2D(128, (7, 7), activation='relu', padding='same')(reshape_bottleneck)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    up1 = UpSampling2D((2, 2))(conv4)\n",
    "    conv5 = Conv2D(64, (7, 7), activation='relu', padding='same')(up1)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    up2 = UpSampling2D((2, 2))(conv5)\n",
    "    conv6 = Conv2D(1, (7, 7), activation='sigmoid', padding='same')(up2)\n",
    "\n",
    "    return conv6\n",
    "\n",
    "# Input layer\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "# Create the encoder and models\n",
    "encoder_model = Model(input_img, encoder(input_img))\n",
    "\n",
    "# autoencoder model\n",
    "autoencoder_model = Model(input_img, decoder(encoder(input_img)))\n",
    "\n",
    "# decoder model\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "decoder_output = decoder(decoder_input)\n",
    "decoder_model = Model(decoder_input, decoder_output)\n",
    "\n",
    "# Compile the autoencoder model (not necessary for the decoder only model)\n",
    "encoder_model.compile(loss='mean_squared_error', optimizer=RMSprop(0.01))\n",
    "autoencoder_model.compile(loss='mean_squared_error', optimizer=RMSprop(0.01))\n",
    "\n",
    "# Print model summaries\n",
    "encoder_model.summary()\n",
    "autoencoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 9/63 [===>..........................] - ETA: 1:22 - loss: 0.2249"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m autoencoder_train \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ground\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_ground\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder_train = autoencoder_model.fit(train_X, train_ground, batch_size=batch_size, epochs=epochs, verbose=1,validation_data=(valid_X, valid_ground))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = autoencoder_train.history['loss']\n",
    "val_loss = autoencoder_train.history['val_loss']\n",
    "epochs = range(epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, '-r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, '-g', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the models\n",
    "autoencoder_model.save('autoencoder.h5')\n",
    "encoder_model.save('encoder.h5')\n",
    "decoder_model.save('decoder.h5')  # Save the decoder model separately\n",
    "\n",
    "# Predict the autoencoder output from test images\n",
    "pred = autoencoder_model.predict(test_data)\n",
    "\n",
    "# Predict the encoder output from test images\n",
    "encoded_data = encoder_model.predict(test_data)\n",
    "\n",
    "# Generate 10 random indices\n",
    "random_indices = np.random.choice(test_data.shape[0], size=10, replace=False)\n",
    "\n",
    "for j in range(10):\n",
    "    index = random_indices[j]\n",
    "    print(\n",
    "        f'=========================================================== Image {j+1} ===========================================================')\n",
    "\n",
    "    # Display the original image in a separate plot\n",
    "    fig_original, ax_original = plt.subplots(figsize=(2, 2))\n",
    "    ax_original.imshow(test_data[index, :, :, 0], cmap='gray')\n",
    "    ax_original.set_title('Original')\n",
    "    ax_original.get_xaxis().set_visible(False)\n",
    "    ax_original.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "    # Display the image after reconstruction\n",
    "    fig_reconstructed, ax_reconstructed = plt.subplots(figsize=(2, 2))\n",
    "    ax_reconstructed.imshow(pred[index, :, :, 0], cmap='gray')\n",
    "    ax_reconstructed.set_title('Reconstructed')\n",
    "    ax_reconstructed.get_xaxis().set_visible(False)\n",
    "    ax_reconstructed.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "    # Obtain encoded representation using the encoder model\n",
    "    encoded_representation = encoder_model.predict(test_data[index:index + 1])\n",
    "    \n",
    "    # Display the encoded representation\n",
    "    print(f'Encoded Representation Shape: {encoded_representation.shape}')\n",
    "\n",
    "    # Obtain decoded representation using the decoder model\n",
    "    decoded_representation = decoder_model.predict(encoded_representation)\n",
    "    \n",
    "    # Display the decoded representation\n",
    "    fig_decoded, ax_decoded = plt.subplots(figsize=(2, 2))\n",
    "    ax_decoded.imshow(decoded_representation[0, :, :, 0], cmap='gray')\n",
    "    ax_decoded.set_title('Decoded')\n",
    "    ax_decoded.get_xaxis().set_visible(False)\n",
    "    ax_decoded.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
